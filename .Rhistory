oil.price
help(window)
acf(as.vector(co2), log.max=36)
plot(diff(co2), ylab="Diff", xlab="time")
points(window(co2, start=c(2000, 1)), pch=Month)
acf(as.vector(co2), lag.max=36)
acf(as.vector(co2), lag.max = 36)
acf(as.vector(co2), lag.max = 36)
acf(as.vector(diff(co2)), lag.max = 36)
plot(diff(diff(co2),lag=12),xlab="time", yLab="two diff")
acf(as.vector(diff(diff(co2), lag=12)), lag.max=36,ci.type="ma")
m1.co2=arima(co2, order=c(0,1,1), seasonal = list(order=c(0,1,1), period=12))
m1.co2
help(rstandard)
help(list)
plot(window(rstandard(m1.co2), start=c(1995, 2)), ylab="Standard Residuals", type="o")
qqnorm(window(rstandard(m1.co2),start=c(1995,2)))
qqline(window(rstandard(m1.co2),start=c(1995,2)))
m2.co2=arima(co2, order=c(0,1,2), seasonal = list(order=c(0,1,2), period=12))
m2.co2
m2.co2=arima(co2, order=c(0,1,2), seasonal = list(order=c(0,1,1), period=12))
plot(m1.co2, n1=c(2003,1), n.ahead = 24, xlab='year', type='o',ylab="co2 level")
plot(m1.co2)
plot(m1.co2, n1=c(2003,1), n.ahead = 24, xlab='year', type='o',ylab="co2 level")
plot(m1.co2, n1=c(2004,1), n.ahead = 48, xlab='year', type='0', ylab="co2 level")
plot(m1.co2, n1=c(2004,1), n.ahead = 48, xlab='year', type='o', ylab="co2 level")
plot(m1.co2, n1=c(2003,1), n.ahead = 48, xlab='year', type='o', ylab="co2 level")
m2.co2
predict(m2.co2, n1=c(2003,1), n.ahead = 48)
predict(m2.co2, n1=c(2003,1), n.ahead = 48)
model = fitted(m2.co2)
predict(model, n1=c(2003,1), n.head=48)
predict(m2.co2, n1=c(2003,1), n.head=48)
predict(model, n1=c(2003,1), n.head=48)
help("predict")
help("fitted")
help("fitted.Arima")
help("predict.Arima")
a <- "aa"
a
a="aa"
a
predict(m1.co2, 1)
predict(m1.co2, 2)
predict(m1.co2, 3)
m1.co2
co2
help("read.csv")
read.csv("D:\practicespace\github\predictionPlatform\dataset\co2.csv")
read.csv("D:\\practicespace\\github\\predictionPlatform\\dataset\\co2.csv")
type(m2.co2)
typeof(m2.co2)
typeof(d)
da = read.csv("D:\\practicespace\\github\\predictionPlatform\\dataset\\co2.csv")
typeof(da)
help(list)
m2.co2
co2
summary(co2)
student<-data.frame(ID=c(11,12,13),Name=c("Devin","Edward","Wenli"),Gender=c("M","M","F"),Birthdate=c("1984-12-29","1983-5-6","1986-8-8”))
student<-data.frame(ID=c(11,12,13),Name=c("Devin","Edward","Wenli"),Gender=c("M","M","F"),Birthdate=c("1984-12-29","1983-5-6","1986-8-8”))
student=ata.frame(ID=c(11,12,13),Name=c("Devin","Edward","Wenli"),Gender=c("M","M","F"),Birthdate=c("1984-12-29","1983-5-6","1986-8-8”))
student=data.frame(ID=c(11,12,13),Name=c("Devin","Edward","Wenli"),Gender=c("M","M","F"),Birthdate=c("1984-12-29","1983-5-6","1986-8-8”))
student=data.frame(ID=c(11,12,13),Name=c("Devin","Edward","Wenli"),Gender=c("M","M","F"),Birthdate=c("1984-12-29","1983-5-6","1986-8-8”))
student=data.frame(ID=c(11,12,13),Name=c("Devin","Edward","Wenli"))
student=data.frame(ID=c(11,12,13),Name=c("Devin","Edward","Wenli"))
typeof(student)
help("data.frame")
da = read.csv("D:\\practicespace\\github\\predictionPlatform\\dataset\\co2.csv")
data.frame(da, row.names = "year")
da = read.csv("D:\\practicespace\\github\\predictionPlatform\\dataset\\co2.csv")
da2 = data.frame(da, row.names = "year")
da2
m2.co2
co2
trend =  read.csv("D:\\practicespace\\github\\predictionPlatform\\dataset\\SalesTrend.csv")
data.frame(co2, row.names = "year")
install.packages(sqldf)
install.packages("sqldf")
library(sqldf)
df = sqldf('select REPORT_DATE, sum(QLI) from df group by REPORT_DATE')
data(df)
trend =  read.csv("D:\\practicespace\\github\\predictionPlatform\\dataset\\SalesTrend.csv")
df = data.frame(tends)
library(sqldf)
df = sqldf('select REPORT_DATE, sum(QLI) from df group by REPORT_DATE')
df
df = data.frame(tends)
df
trend =  read.csv("D:\\practicespace\\github\\predictionPlatform\\dataset\\SalesTrend.csv")
df = data.frame(tends)
trends =  read.csv("D:\\practicespace\\github\\predictionPlatform\\dataset\\SalesTrend.csv")
df = data.frame(tends)
df = data.frame(trends)
library(sqldf)
df = sqldf('select REPORT_DATE, sum(QLI) from df group by REPORT_DATE')
trends =  read.csv("D:\\practicespace\\github\\predictionPlatform\\dataset\\SalesTrend.csv")
df = data.frame(trends)
df
df.head()
head(df)
df_group = sqldf('select REPORT_DATE, sum(QLI) from 锘縍EPORT_DATE group by REPORT_DATE')
df_group = sqldf('select 锘縍EPORT_DATE, sum(QLI) from df group by REPORT_DATE')
trends =  read.csv("D:\\practicespace\\github\\predictionPlatform\\dataset\\SalesTrend.csv")
df = data.frame(trends)
head(df)
df_group = sqldf('select 锘縍EPORT_DATE, sum(QLI) from df group by REPORT_DATE')
library(sqldf)
df_group = sqldf('select EPORT_DATE_2, sum(QLI) from df group by REPORT_DATE')
trends =  read.csv("D:\\practicespace\\github\\predictionPlatform\\dataset\\SalesTrend.csv")
df = data.frame(trends)
head(df)
trends =  read.csv("D:\\practicespace\\github\\predictionPlatform\\dataset\\SalesTrend.csv")
df = data.frame(trends)
head(df)
trends =  read.csv("D:\\practicespace\\github\\predictionPlatform\\dataset\\SalesTrend.csv")
df = data.frame(trends)
head(df)
trends =  read.csv("D:\\practicespace\\github\\predictionPlatform\\dataset\\SalesTrend.csv")
df = data.frame(trends)
head(df)
trends =  read.csv("D:\\practicespace\\github\\predictionPlatform\\dataset\\SalesTrend.csv")
df = data.frame(trends)
head(df)
df_group = sqldf('select EPORT_DATE_2, sum(QLI) from df group by REPORT_DATE')
df_group = sqldf('select EPORT_DATE, sum(QLI) from df group by REPORT_DATE')
df_group = sqldf('select REPORT_DATE, sum(QLI) from df group by REPORT_DATE')
df_group
len(df_group)
summary(df_group)
df_group = sqldf('select REPORT_DATE, sum(QLI) as QLI from df group by REPORT_DATE')
df_group
summary(df_group)
head(df,2)
df =  read.csv("D:\\practicespace\\github\\predictionPlatform\\dataset\\SalesTrend.csv")
#df = data.frame(trends)
head(df,2)
summary(df_group)
install.packages("caret")
install.packages("caret")
install.packages("randomForest")
setwd("d:/practicespace/github/predictionPlatform")
library(randomForest)
library(sqldf)
library(CrossR)
library(caret)
df = read.csv("dataset\\SalesTrend.csv")
head(df, 1)
trend = sqldf("select REPORT_DATE, sum(QLI) as QLI
,avg(LAST_1_MONTH_AVG) as LAST_1_MONTH_AVG
,avg(LAST_1_MONTH_MIN) as LAST_1_MONTH_MIN
,avg(LAST_1_MONTH_MAX) as LAST_1_MONTH_MAX
,avg(LAST_1_MONTH_SUM) as LAST_1_MONTH_SUM
,avg(LAST_1_MONTH_MID) as LAST_1_MONTH_MID
,avg(LAST_1_MONTH_MID25) as LAST_1_MONTH_MID25
,avg(LAST_1_MONTH_MID75) as LAST_1_MONTH_MID75
,avg(LAST_2_MONTH_AVG) as LAST_2_MONTH_AVG
,avg(LAST_2_MONTH_MIN) as LAST_2_MONTH_MIN
,avg(LAST_2_MONTH_MAX) as LAST_2_MONTH_MAX
,avg(LAST_2_MONTH_SUM) as LAST_2_MONTH_SUM
,avg(LAST_2_MONTH_MID) as LAST_2_MONTH_MID
,avg(LAST_2_MONTH_MID25) as LAST_2_MONTH_MID25
,avg(LAST_2_MONTH_MID75) as LAST_2_MONTH_MID75
,avg(LAST_3_MONTH_AVG) as LAST_3_MONTH_AVG
,avg(LAST_3_MONTH_MIN) as LAST_3_MONTH_MIN
,avg(LAST_3_MONTH_MAX) as LAST_3_MONTH_MAX
,avg(LAST_3_MONTH_SUM) as LAST_3_MONTH_SUM
,avg(LAST_3_MONTH_MID) as LAST_3_MONTH_MID
,avg(LAST_3_MONTH_MID25) as LAST_3_MONTH_MID25
,avg(LAST_3_MONTH_MID75) as LAST_3_MONTH_MID75
,avg(LAST_4_MONTH_AVG) as LAST_4_MONTH_AVG
,avg(LAST_4_MONTH_MIN) as LAST_4_MONTH_MIN
,avg(LAST_4_MONTH_MAX) as LAST_4_MONTH_MAX
,avg(LAST_4_MONTH_SUM) as LAST_4_MONTH_SUM
,avg(LAST_4_MONTH_MID) as LAST_4_MONTH_MID
,avg(LAST_4_MONTH_MID25) as LAST_4_MONTH_MID25
,avg(LAST_4_MONTH_MID75) as LAST_4_MONTH_MID75
,avg(LAST_5_MONTH_AVG) as LAST_5_MONTH_AVG
,avg(LAST_5_MONTH_MIN) as LAST_5_MONTH_MIN
,avg(LAST_5_MONTH_MAX) as LAST_5_MONTH_MAX
,avg(LAST_5_MONTH_SUM) as LAST_5_MONTH_SUM
,avg(LAST_5_MONTH_MID) as LAST_5_MONTH_MID
,avg(LAST_5_MONTH_MID25) as LAST_5_MONTH_MID25
,avg(LAST_5_MONTH_MID75) as LAST_5_MONTH_MID75
,avg(LAST_6_MONTH_AVG) as LAST_6_MONTH_AVG
,avg(LAST_6_MONTH_MIN) as LAST_6_MONTH_MIN
,avg(LAST_6_MONTH_MAX) as LAST_6_MONTH_MAX
,avg(LAST_6_MONTH_SUM) as LAST_6_MONTH_SUM
,avg(LAST_6_MONTH_MID) as LAST_6_MONTH_MID
,avg(LAST_6_MONTH_MID25) as LAST_6_MONTH_MID25
,avg(LAST_6_MONTH_MID75) as LAST_6_MONTH_MID75
,avg(LAST_12_MONTH_AVG) as LAST_12_MONTH_AVG
,avg(LAST_12_MONTH_MIN) as LAST_12_MONTH_MIN
,avg(LAST_12_MONTH_MAX) as LAST_12_MONTH_MAX
,avg(LAST_12_MONTH_SUM) as LAST_12_MONTH_SUM
,avg(LAST_12_MONTH_MID) as LAST_12_MONTH_MID
,avg(LAST_12_MONTH_MID25) as LAST_12_MONTH_MID25
,avg(LAST_12_MONTH_MID75) as LAST_12_MONTH_MID75
from df where BANNER_NAME='Carrefour' group by REPORT_DATE")
banner_group_raw = read.csv("dataset\\banner_group.csv")
banner_group=banner_group_raw[-2]
head(banner_group)
banner_trend = merge(trend, banner_group, by="REPORT_DATE")
head(df_trend, 3)
#y = df_trend[["QLI"]]
#X = df_trend[-2]
#splitSet = train_test_split(X, y, test_size=0.2)
#X_train = splitSet$X_train
#y_train = splitSet$y_train
#X_test = splitSet$X_test
#y_test = splitSet$y_test
#head(X_train, 1)
trainIndex = createDataPartition(df_trend$QLI,
p=0.8, list=FALSE,times=1)
train = df_trend[trainIndex,]
test = df_trend[-trainIndex,]
rf = randomForest(QLI~., data=train,mtry=3,
importance=TRUE, na.action=na.omit)
df_trend["REPORT_DATE"]
banner_trend = merge(trend, banner_group, by="REPORT_DATE")
#head(df_trend, 3)
#y = df_trend[["QLI"]]
#X = df_trend[-2]
#splitSet = train_test_split(X, y, test_size=0.2)
#X_train = splitSet$X_train
#y_train = splitSet$y_train
#X_test = splitSet$X_test
#y_test = splitSet$y_test
#head(X_train, 1)
trainIndex = createDataPartition(banner_trend$QLI,
p=0.8, list=FALSE,times=1)
train = banner_trend[trainIndex,]
test = banner_trend[-trainIndex,]
rf = randomForest(QLI~., data=train,mtry=3,
importance=TRUE, na.action=na.omit)
trainIndex = createDataPartition(banner_trend$QLI,
p=0.8, list=FALSE,times=1)
train = banner_trend[trainIndex,]
test = banner_trend[-trainIndex,]
trainIndex = createDataPartition(banner_trend$QLI,
p=0.8, list=FALSE,times=1)
train = banner_trend[trainIndex,]
test = banner_trend[-trainIndex,]
library(caret)
library(caret)
install.packages("caret")
library(caret)
install.packages("Rcpp11")
install.packages("Rcpp")
install.packages("Rcpp")
installed.packages()
library("caret")
trainIndex = createDataPartition(banner_trend$QLI,
p=0.8, list=FALSE,times=1)
train = banner_trend[trainIndex,]
test = banner_trend[-trainIndex,]
rf = randomForest(QLI~., data=train,mtry=3,
importance=TRUE, na.action=na.omit)
banner_trend["REPORT_DATE"]
library("ggplot2")
install.packages(ggplot2)
install.packages(tibble)
install.packages("tibble")
install.packages("ggplot2")
library(caret)
trainIndex = createDataPartition(banner_trend$QLI,
p=0.8, list=FALSE,times=1)
train = banner_trend[trainIndex,]
test = banner_trend[-trainIndex,]
rf = randomForest(QLI~., data=train,mtry=3,
importance=TRUE, na.action=na.omit)
banner_trend["REPORT_DATE"]
install.packages("randomForest")
trainIndex = createDataPartition(banner_trend$QLI,
p=0.8, list=FALSE,times=1)
train = banner_trend[trainIndex,]
test = banner_trend[-trainIndex,]
rf = randomForest(QLI~., data=train,mtry=3,
importance=TRUE, na.action=na.omit)
banner_trend["REPORT_DATE"]
library(randomForest)
library(sqldf)
library(caret)
df = read.csv("dataset\\SalesTrend.csv")
head(df, 1)
trend = sqldf("select REPORT_DATE, sum(QLI) as QLI
,avg(LAST_1_MONTH_AVG) as LAST_1_MONTH_AVG
,avg(LAST_1_MONTH_MIN) as LAST_1_MONTH_MIN
,avg(LAST_1_MONTH_MAX) as LAST_1_MONTH_MAX
,avg(LAST_1_MONTH_SUM) as LAST_1_MONTH_SUM
,avg(LAST_1_MONTH_MID) as LAST_1_MONTH_MID
,avg(LAST_1_MONTH_MID25) as LAST_1_MONTH_MID25
,avg(LAST_1_MONTH_MID75) as LAST_1_MONTH_MID75
,avg(LAST_2_MONTH_AVG) as LAST_2_MONTH_AVG
,avg(LAST_2_MONTH_MIN) as LAST_2_MONTH_MIN
,avg(LAST_2_MONTH_MAX) as LAST_2_MONTH_MAX
,avg(LAST_2_MONTH_SUM) as LAST_2_MONTH_SUM
,avg(LAST_2_MONTH_MID) as LAST_2_MONTH_MID
,avg(LAST_2_MONTH_MID25) as LAST_2_MONTH_MID25
,avg(LAST_2_MONTH_MID75) as LAST_2_MONTH_MID75
,avg(LAST_3_MONTH_AVG) as LAST_3_MONTH_AVG
,avg(LAST_3_MONTH_MIN) as LAST_3_MONTH_MIN
,avg(LAST_3_MONTH_MAX) as LAST_3_MONTH_MAX
,avg(LAST_3_MONTH_SUM) as LAST_3_MONTH_SUM
,avg(LAST_3_MONTH_MID) as LAST_3_MONTH_MID
,avg(LAST_3_MONTH_MID25) as LAST_3_MONTH_MID25
,avg(LAST_3_MONTH_MID75) as LAST_3_MONTH_MID75
,avg(LAST_4_MONTH_AVG) as LAST_4_MONTH_AVG
,avg(LAST_4_MONTH_MIN) as LAST_4_MONTH_MIN
,avg(LAST_4_MONTH_MAX) as LAST_4_MONTH_MAX
,avg(LAST_4_MONTH_SUM) as LAST_4_MONTH_SUM
,avg(LAST_4_MONTH_MID) as LAST_4_MONTH_MID
,avg(LAST_4_MONTH_MID25) as LAST_4_MONTH_MID25
,avg(LAST_4_MONTH_MID75) as LAST_4_MONTH_MID75
,avg(LAST_5_MONTH_AVG) as LAST_5_MONTH_AVG
,avg(LAST_5_MONTH_MIN) as LAST_5_MONTH_MIN
,avg(LAST_5_MONTH_MAX) as LAST_5_MONTH_MAX
,avg(LAST_5_MONTH_SUM) as LAST_5_MONTH_SUM
,avg(LAST_5_MONTH_MID) as LAST_5_MONTH_MID
,avg(LAST_5_MONTH_MID25) as LAST_5_MONTH_MID25
,avg(LAST_5_MONTH_MID75) as LAST_5_MONTH_MID75
,avg(LAST_6_MONTH_AVG) as LAST_6_MONTH_AVG
,avg(LAST_6_MONTH_MIN) as LAST_6_MONTH_MIN
,avg(LAST_6_MONTH_MAX) as LAST_6_MONTH_MAX
,avg(LAST_6_MONTH_SUM) as LAST_6_MONTH_SUM
,avg(LAST_6_MONTH_MID) as LAST_6_MONTH_MID
,avg(LAST_6_MONTH_MID25) as LAST_6_MONTH_MID25
,avg(LAST_6_MONTH_MID75) as LAST_6_MONTH_MID75
,avg(LAST_12_MONTH_AVG) as LAST_12_MONTH_AVG
,avg(LAST_12_MONTH_MIN) as LAST_12_MONTH_MIN
,avg(LAST_12_MONTH_MAX) as LAST_12_MONTH_MAX
,avg(LAST_12_MONTH_SUM) as LAST_12_MONTH_SUM
,avg(LAST_12_MONTH_MID) as LAST_12_MONTH_MID
,avg(LAST_12_MONTH_MID25) as LAST_12_MONTH_MID25
,avg(LAST_12_MONTH_MID75) as LAST_12_MONTH_MID75
from df where BANNER_NAME='Carrefour' group by REPORT_DATE")
banner_group_raw = read.csv("dataset\\banner_group.csv")
banner_group=banner_group_raw[-2]
head(banner_group)
banner_trend = merge(trend, banner_group, by="REPORT_DATE")
#head(df_trend, 3)
#y = df_trend[["QLI"]]
#X = df_trend[-2]
#splitSet = train_test_split(X, y, test_size=0.2)
#X_train = splitSet$X_train
#y_train = splitSet$y_train
#X_test = splitSet$X_test
#y_test = splitSet$y_test
#head(X_train, 1)
trainIndex = createDataPartition(banner_trend$QLI,
p=0.8, list=FALSE,times=1)
train = banner_trend[trainIndex,]
test = banner_trend[-trainIndex,]
rf = randomForest(QLI~., data=train,mtry=3,
importance=TRUE, na.action=na.omit)
banner_trend["REPORT_DATE"]
banner_trend$QLI
dim(banner_trend)
dim(banner_trend)
dim(df)
dim(banner_group_raw)
dim(banner_trend)
df = read.csv("dataset\\SalesTrend.csv")
dim(df)
trend = sqldf("select REPORT_DATE, sum(QLI) as QLI
,avg(LAST_1_MONTH_AVG) as LAST_1_MONTH_AVG
,avg(LAST_1_MONTH_MIN) as LAST_1_MONTH_MIN
,avg(LAST_1_MONTH_MAX) as LAST_1_MONTH_MAX
,avg(LAST_1_MONTH_SUM) as LAST_1_MONTH_SUM
,avg(LAST_1_MONTH_MID) as LAST_1_MONTH_MID
,avg(LAST_1_MONTH_MID25) as LAST_1_MONTH_MID25
,avg(LAST_1_MONTH_MID75) as LAST_1_MONTH_MID75
,avg(LAST_2_MONTH_AVG) as LAST_2_MONTH_AVG
,avg(LAST_2_MONTH_MIN) as LAST_2_MONTH_MIN
,avg(LAST_2_MONTH_MAX) as LAST_2_MONTH_MAX
,avg(LAST_2_MONTH_SUM) as LAST_2_MONTH_SUM
,avg(LAST_2_MONTH_MID) as LAST_2_MONTH_MID
,avg(LAST_2_MONTH_MID25) as LAST_2_MONTH_MID25
,avg(LAST_2_MONTH_MID75) as LAST_2_MONTH_MID75
,avg(LAST_3_MONTH_AVG) as LAST_3_MONTH_AVG
,avg(LAST_3_MONTH_MIN) as LAST_3_MONTH_MIN
,avg(LAST_3_MONTH_MAX) as LAST_3_MONTH_MAX
,avg(LAST_3_MONTH_SUM) as LAST_3_MONTH_SUM
,avg(LAST_3_MONTH_MID) as LAST_3_MONTH_MID
,avg(LAST_3_MONTH_MID25) as LAST_3_MONTH_MID25
,avg(LAST_3_MONTH_MID75) as LAST_3_MONTH_MID75
,avg(LAST_4_MONTH_AVG) as LAST_4_MONTH_AVG
,avg(LAST_4_MONTH_MIN) as LAST_4_MONTH_MIN
,avg(LAST_4_MONTH_MAX) as LAST_4_MONTH_MAX
,avg(LAST_4_MONTH_SUM) as LAST_4_MONTH_SUM
,avg(LAST_4_MONTH_MID) as LAST_4_MONTH_MID
,avg(LAST_4_MONTH_MID25) as LAST_4_MONTH_MID25
,avg(LAST_4_MONTH_MID75) as LAST_4_MONTH_MID75
,avg(LAST_5_MONTH_AVG) as LAST_5_MONTH_AVG
,avg(LAST_5_MONTH_MIN) as LAST_5_MONTH_MIN
,avg(LAST_5_MONTH_MAX) as LAST_5_MONTH_MAX
,avg(LAST_5_MONTH_SUM) as LAST_5_MONTH_SUM
,avg(LAST_5_MONTH_MID) as LAST_5_MONTH_MID
,avg(LAST_5_MONTH_MID25) as LAST_5_MONTH_MID25
,avg(LAST_5_MONTH_MID75) as LAST_5_MONTH_MID75
,avg(LAST_6_MONTH_AVG) as LAST_6_MONTH_AVG
,avg(LAST_6_MONTH_MIN) as LAST_6_MONTH_MIN
,avg(LAST_6_MONTH_MAX) as LAST_6_MONTH_MAX
,avg(LAST_6_MONTH_SUM) as LAST_6_MONTH_SUM
,avg(LAST_6_MONTH_MID) as LAST_6_MONTH_MID
,avg(LAST_6_MONTH_MID25) as LAST_6_MONTH_MID25
,avg(LAST_6_MONTH_MID75) as LAST_6_MONTH_MID75
,avg(LAST_12_MONTH_AVG) as LAST_12_MONTH_AVG
,avg(LAST_12_MONTH_MIN) as LAST_12_MONTH_MIN
,avg(LAST_12_MONTH_MAX) as LAST_12_MONTH_MAX
,avg(LAST_12_MONTH_SUM) as LAST_12_MONTH_SUM
,avg(LAST_12_MONTH_MID) as LAST_12_MONTH_MID
,avg(LAST_12_MONTH_MID25) as LAST_12_MONTH_MID25
,avg(LAST_12_MONTH_MID75) as LAST_12_MONTH_MID75
from df where BANNER_NAME='Carrefour' group by REPORT_DATE")
banner_group_raw = read.csv("dataset\\banner_group.csv")
dim(banner_group_raw)
banner_group=banner_group_raw[-2]
head(banner_group)
banner_trend = merge(trend, banner_group, by="REPORT_DATE")
dim(banner_trend)
trainIndex = createDataPartition(banner_trend$QLI,
p=0.8, list=FALSE,times=1)
train = banner_trend[trainIndex,]
test = banner_trend[-trainIndex,]
rf = randomForest(QLI~., data=train,mtry=3,
importance=TRUE, na.action=na.omit)
banner_trend["REPORT_DATE"]
rf = randomForest(QLI~., data=train,mtry=3,
importance=TRUE, na.action=na.omit)
rf = randomForest(QLI~LAST_1_MONTH_AVG+LAST_12_MONTH_MIN, data=train,mtry=3,
importance=TRUE, na.action=na.omit)
banner_trend["REPORT_DATE"]
rf = randomForest(QLI~., data=train,mtry=3,
importance=TRUE, na.action=na.omit)
rf = randomForest(QLI~IS_CHRISTMAS+LAST_1_MONTH_AVG+LAST_1_MONTH_MID75+LAST_1_MONTH_MAX+LAST_1_MONTH_SUM+LAST_1_MONTH_MID+LAST_2_MONTH_AVG+LAST_1_MONTH_MID25+LAST_2_MONTH_MAX+LAST_2_MONTH_SUM+LAST_2_MONTH_MID75+WEEK_OF_YEARMONTH_OF_YEAR+LAST_2_MONTH_MID+LAST_2_MONTH_MID25+LAST_3_MONTH_AVG+LAST_3_MONTH_MAXLAST_1_MONTH_MIN+LAST_3_MONTH_MID25+LAST_3_MONTH_SUM, data=train,mtry=3,
importance=TRUE, na.action=na.omit)
rf = randomForest(QLI~IS_CHRISTMAS+LAST_1_MONTH_AVG
+LAST_1_MONTH_MID75
+LAST_1_MONTH_MAX
+LAST_1_MONTH_SUM
+LAST_1_MONTH_MID
+LAST_2_MONTH_AVG
+LAST_1_MONTH_MID25
+LAST_2_MONTH_MAX
+LAST_2_MONTH_SUM
+LAST_2_MONTH_MID75
+WEEK_OF_YEAR
+MONTH_OF_YEAR
+LAST_2_MONTH_MID
+LAST_2_MONTH_MID25
+LAST_3_MONTH_AVG
+LAST_3_MONTH_MAXLAST_1_MONTH_MIN
+LAST_3_MONTH_MID25
+LAST_3_MONTH_SUM, data=train,mtry=3,
importance=TRUE, na.action=na.omit)
rf = randomForest(QLI~IS_CHRISTMAS
+LAST_1_MONTH_AVG
+LAST_1_MONTH_MID75
+LAST_1_MONTH_MAX
+LAST_1_MONTH_SUM
+LAST_1_MONTH_MID
+LAST_2_MONTH_AVG
+LAST_1_MONTH_MID25
+LAST_2_MONTH_MAX
+LAST_2_MONTH_SUM
+LAST_2_MONTH_MID75
+WEEK_OF_YEAR
+MONTH_OF_YEAR
+LAST_2_MONTH_MID
+LAST_2_MONTH_MID25
+LAST_3_MONTH_AVG
+LAST_3_MONTH_MAX
+LAST_1_MONTH_MIN
+LAST_3_MONTH_MID25
+LAST_3_MONTH_SUM, data=train,mtry=3,
importance=TRUE, na.action=na.omit)
fitted(rf)
importance=TRUE, na.action=na.omit)
help("randomForest")
banner_trend = sqldf("select QLI
,LAST_1_MONTH_AVG
,LAST_1_MONTH_MID75
,LAST_1_MONTH_MAX
,LAST_1_MONTH_SUM
,LAST_1_MONTH_MID
,LAST_2_MONTH_AVG
,LAST_1_MONTH_MID25
,LAST_2_MONTH_MAX
,LAST_2_MONTH_SUM
,LAST_2_MONTH_MID75
,WEEK_OF_YEAR
,MONTH_OF_YEAR
,LAST_2_MONTH_MID
,LAST_2_MONTH_MID25
,LAST_3_MONTH_AVG
,LAST_3_MONTH_MAX
,LAST_1_MONTH_MIN
,LAST_3_MONTH_MID25
,LAST_3_MONTH_SUM
from banner_trend")
#head(df_trend, 3)
#y = df_trend[["QLI"]]
#X = df_trend[-2]
#splitSet = train_test_split(X, y, test_size=0.2)
#X_train = splitSet$X_train
#y_train = splitSet$y_train
#X_test = splitSet$X_test
#y_test = splitSet$y_test
#head(X_train, 1)
trainIndex = createDataPartition(banner_trend$QLI,
p=0.8, list=FALSE,times=1)
